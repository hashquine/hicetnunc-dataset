{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../../src/reload.py\n",
    "import src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading parsed logs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 1/21405 [00:00<1:05:56,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making tokens db...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21405/21405 [00:25<00:00, 850.99it/s]\n",
      "  1%|█                                                                                                                                           | 197/25052 [00:00<00:15, 1575.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making swaps db...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25052/25052 [00:15<00:00, 1622.85it/s]\n",
      "  0%|▌                                                                                                                                             | 90/21405 [00:00<00:38, 548.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating tokens with info...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21405/21405 [00:34<00:00, 620.11it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "print('Reading parsed logs...')\n",
    "\n",
    "nft_state_log = src.utils.read_json(src.config.nft_state_log_file)\n",
    "nft_state = src.contracts.nft_state.NFTState()\n",
    "nft_state_replayer = src.contracts.state_utils.StateReplayer(nft_state_log, nft_state)\n",
    "\n",
    "ah_state_log = src.utils.read_json(src.config.ah_state_log_file)\n",
    "ah_state = src.contracts.art_house_state.ArtHouseState()\n",
    "ah_state_replayer = src.contracts.state_utils.StateReplayer(ah_state_log, ah_state)\n",
    "\n",
    "money_state_log = src.utils.read_json(src.config.money_state_log_file)\n",
    "money_state = src.contracts.money_state.MoneyState()\n",
    "money_state_replayer = src.contracts.state_utils.StateReplayer(money_state_log, money_state)\n",
    "\n",
    "addrs_state_log = src.utils.read_json(src.config.addrs_state_log_file)\n",
    "addrs_state = src.contracts.addrs_state.AddrsState()\n",
    "addrs_state_replayer = src.contracts.state_utils.StateReplayer(addrs_state_log, addrs_state)\n",
    "\n",
    "tr_info_db = src.tr.info_db.TrInfoDB()\n",
    "\n",
    "nft_state_replayer.replay_to_end()\n",
    "ah_state_replayer.replay_to_end()\n",
    "money_state_replayer.replay_to_end()\n",
    "addrs_state_replayer.replay_to_end()\n",
    "\n",
    "\n",
    "print('Making tokens db...')\n",
    "\n",
    "tokens_db = {}\n",
    "swaps_db = {}\n",
    "\n",
    "assert set(nft_state.tokens.keys()) == set(ah_state.tokens.keys())\n",
    "\n",
    "for token_id, nft_token_info in nft_state.tokens.items():\n",
    "    tokens_db[str(token_id)] = {\n",
    "        'token_id': token_id,\n",
    "        'creator': nft_token_info['creator'],\n",
    "        'mint_tokens_receiver': nft_token_info['tokens_receiver'],\n",
    "        'info_ipfs': nft_token_info['info_ipfs'],\n",
    "        'mint_count': nft_token_info['mint_count'],\n",
    "        'mint_row_id': nft_token_info['mint_row_id'],\n",
    "    }\n",
    "\n",
    "for token_id, ah_token_info in tqdm(ah_state.tokens.items()):\n",
    "    db_entry = tokens_db[str(token_id)]\n",
    "    db_entry['royalties'] = ah_token_info['royalties']\n",
    "    db_entry['mint_ah_row_id'] = ah_token_info['mint_ah_row_id']\n",
    "\n",
    "    assert db_entry['mint_tokens_receiver'] == ah_token_info['tokens_receiver']\n",
    "    assert db_entry['mint_count'] == ah_token_info['mint_count']\n",
    "    assert db_entry['info_ipfs'] == ah_token_info['info_ipfs']\n",
    "\n",
    "    nft_mint_tr = tr_info_db.get_full_tr_by_row_id(db_entry['mint_row_id'])\n",
    "    ah_mint_tr = tr_info_db.get_full_tr_by_row_id(ah_token_info['mint_ah_row_id'])\n",
    "    assert nft_mint_tr == ah_mint_tr\n",
    "\n",
    "\n",
    "print('Making swaps db...')\n",
    "\n",
    "for swap_id, ah_swap_info in tqdm(list(ah_state.swaps.items())):\n",
    "    assert str(ah_swap_info['token_id']) in tokens_db\n",
    "    ah_swap_op = tr_info_db.get_full_tr_by_row_id(ah_swap_info['created_row_id'], return_op=True)\n",
    "    swaps_db[str(swap_id)] = {\n",
    "        'swap_id': swap_id,\n",
    "        'created_row_id': ah_swap_info['created_row_id'],\n",
    "        'token_id': ah_swap_info['token_id'],\n",
    "        'price': ah_swap_info['price'],\n",
    "        'initial_count': ah_swap_info['initial_count'],\n",
    "    }\n",
    "\n",
    "\n",
    "print('Populating tokens with info...')\n",
    "\n",
    "token_info_fields_cnt = Counter()\n",
    "\n",
    "for token_id, token_db_entry in tqdm(tokens_db.items()):\n",
    "    info_ipfs_fpath = src.ipfs.get_ipfs_fpath(token_db_entry['info_ipfs'], 'ipfs0')\n",
    "    token_info = src.utils.read_json(info_ipfs_fpath)\n",
    "\n",
    "    for field in token_info:\n",
    "        token_info_fields_cnt[field] += 1\n",
    "    token_info_keys = set(token_info.keys())\n",
    "    assert token_info_keys.issubset({\n",
    "        'artifactUri', 'creators', 'decimals', 'description', 'displayUri', 'formats',\n",
    "        'isBooleanAmount', 'name', 'shouldPreferSymbol', 'symbol', 'tags', 'thumbnailUri',\n",
    "    })\n",
    "\n",
    "    if int(token_id) == 152:\n",
    "        assert 'isBooleanAmount' not in token_info\n",
    "    elif int(token_id) <= 352:\n",
    "        assert token_info['isBooleanAmount'] == (token_db_entry['mint_count'] == 1)\n",
    "    else:\n",
    "        assert token_info['isBooleanAmount'] is False\n",
    "\n",
    "    if int(token_id) <= 154:\n",
    "        assert 'shouldPreferSymbol' not in token_info\n",
    "    else:\n",
    "        assert token_info['shouldPreferSymbol'] is False\n",
    "\n",
    "    if 'displayUri' in token_info:\n",
    "        assert int(token_id) >= 11000\n",
    "        if token_info['displayUri']:\n",
    "            assert src.ipfs.validate_ipfs_uri(token_info['displayUri'])\n",
    "\n",
    "    assert token_info['decimals'] == 0\n",
    "    assert token_info['thumbnailUri'] == 'ipfs://QmNrhZHUaEqxhyLfqoq1mtHSipkWHeT31LNHb1QEbDHgnc'\n",
    "    assert token_info['symbol'] == 'OBJKT'\n",
    "\n",
    "    assert len(token_info['formats']) == 1\n",
    "    assert token_info['formats'][0]['uri'] == token_info['artifactUri']\n",
    "    assert src.ipfs.validate_ipfs_uri(token_info['formats'][0]['uri'])\n",
    "    assert len(token_info['creators']) == 1\n",
    "\n",
    "    for tag in token_info['tags']:\n",
    "        for ch in [' ', '\\n', '\\t']:\n",
    "            assert ch not in tag, (ch, tag)\n",
    "\n",
    "    if token_info['creators'][0] != token_db_entry['creator']:\n",
    "        assert token_id == '5571' or token_info['creators'][0] in ['', None]\n",
    "\n",
    "    token_db_entry['artifact_mime'] = token_info['formats'][0]['mimeType']\n",
    "    token_db_entry['artifact_ipfs'] = token_info['formats'][0]['uri']\n",
    "    token_db_entry['meta_creator'] = str(token_info['creators'][0])\n",
    "    token_db_entry['display_uri_ipfs'] = token_info.get('displayUri', '') or ''\n",
    "    token_db_entry['tags'] = '\\n'.join(token_info['tags'])\n",
    "    token_db_entry['name'] = token_info['name']\n",
    "    token_db_entry['description'] = token_info['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▎                                                                                                                                          | 202/21405 [00:00<00:10, 2011.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding artifact file size data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████████████▊                                                                                                                       | 3311/21405 [01:15<06:55, 43.57it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mD:\\PycharmProjects\\hicetnunc-dataset\\src\\reload.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mipfs_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mipfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_ipfs_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_db_entry\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'artifact_ipfs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mpreview_fpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreviews_dir\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34m'ps_1000x1000'\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mipfs_id\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.jpeg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mpreview_fpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpreview_fpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mst_size\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreview_fpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pathlib.py\u001b[0m in \u001b[0;36mexists\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1332\u001b[0m         \"\"\"\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mENOTDIR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pathlib.py\u001b[0m in \u001b[0;36mstat\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1154\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mdoes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m         \"\"\"\n\u001b[1;32m-> 1156\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1158\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mowner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pathlib.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(pathobj, *args)\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mstrfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "print('Adding artifact file size data...')\n",
    "\n",
    "not_in_cache_count = 0\n",
    "for token_id, token_db_entry in tqdm(tokens_db.items()):\n",
    "    try:\n",
    "        artifact_fpath = src.ipfs.get_ipfs_fpath(token_db_entry['artifact_ipfs'], 'ipfs1')\n",
    "        token_db_entry['artifact_file_size'] = artifact_fpath.stat().st_size\n",
    "    except IpfsNotCachedException:\n",
    "        not_in_cache_count += 1\n",
    "\n",
    "    ipfs_id = src.ipfs.validate_ipfs_uri(token_db_entry['artifact_ipfs'])\n",
    "    preview_fpath = src.config.previews_dir / 'ps_1000x1000' / (ipfs_id + '.jpeg')\n",
    "    if preview_fpath.exists() and preview_fpath.stat().st_size > 0:\n",
    "        im = Image.open(preview_fpath)\n",
    "        width, height = im.size\n",
    "        token_db_entry['artifact_preview_width'] = width\n",
    "        token_db_entry['artifact_preview_height'] = height\n",
    "\n",
    "    if token_db_entry['display_uri_ipfs'] != '':\n",
    "        try:\n",
    "            display_uri_fpath = src.ipfs.get_ipfs_fpath(token_db_entry['display_uri_ipfs'], 'ipfs1')\n",
    "            token_db_entry['display_uri_file_size'] = display_uri_fpath.stat().st_size\n",
    "        except IpfsNotCachedException:\n",
    "            not_in_cache_count += 1\n",
    "    else:\n",
    "        token_db_entry['display_uri_file_size'] = -1\n",
    "\n",
    "print('Number of tokens without downloaded artifacts:', not_in_cache_count)\n",
    "\n",
    "print('Writing result data...')\n",
    "\n",
    "src.utils.write_json(tokens_db, src.config.tokens_db_json_file)\n",
    "src.utils.write_json(swaps_db, src.config.swaps_db_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown prefixes: {'tz-wrapped/'}\n",
      "Writing addresses database...\n",
      "written 994526 bytes 4105 entries\n"
     ]
    }
   ],
   "source": [
    "addrs_db = {}\n",
    "for addr, addr_entry in addrs_state.addrs.items():\n",
    "    addrs_db[addr] = {\n",
    "        'address': addr,\n",
    "        'first_op_row_id': addr_entry['first_op_row_id'],\n",
    "        'first_op_has_reveal': addr_entry['first_op_has_reveal'],\n",
    "        'in_op_count': addr_entry['in_op_count'],\n",
    "        'out_op_count': addr_entry['out_op_count'],\n",
    "        'money_received': addr_entry['money_received'],\n",
    "        'money_sent': addr_entry['money_sent'],\n",
    "    }\n",
    "\n",
    "accounts_metadata = src.utils.read_json(src.config.tzktio_accounts_metadata_file)\n",
    "\n",
    "url_prefixes = {\n",
    "    'https://www.facebook.com/',\n",
    "    'www.facebook.com/',\n",
    "    'https://facebook.com/',\n",
    "    'https://www.instagram.com/',\n",
    "    'https://instagram.com/',\n",
    "    'https://web.facebook.com/',\n",
    "}\n",
    "\n",
    "unknown_prefixes = set()\n",
    "for addr, addr_meta in accounts_metadata.items():\n",
    "    if addr_meta is None:\n",
    "        continue\n",
    "    db_entry = addrs_db[addr]\n",
    "    for field, field_val in addr_meta.items():\n",
    "        if field in {'twitter', 'site', 'email', 'instagram', 'github', 'telegram', 'reddit', 'facebook'}:\n",
    "            orig_field_val = field_val\n",
    "            field_val = field_val.strip()\n",
    "            if field_val.endswith('/'):\n",
    "                field_val = field_val[:-1]\n",
    "            if field not in {'site', 'email', 'reddit'} and '/' in field_val:\n",
    "                prefix = '/'.join(field_val.lower().split('/')[:-1]) + '/'\n",
    "                if prefix in url_prefixes:\n",
    "                    field_val = field_val[len(prefix):]\n",
    "                else:\n",
    "                    unknown_prefixes.add(prefix)\n",
    "            db_entry[f'tzkt_info_{field}'] = field_val\n",
    "        elif field == 'alias':\n",
    "            db_entry['tzkt_info_name'] = field_val\n",
    "\n",
    "if unknown_prefixes:\n",
    "    print(f'Unknown prefixes: {unknown_prefixes}')\n",
    "\n",
    "print('Writing addresses database...')\n",
    "src.utils.write_json(addrs_db, src.config.addrs_db_json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
